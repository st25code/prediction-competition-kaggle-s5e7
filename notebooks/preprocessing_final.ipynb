{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21965ecc",
   "metadata": {},
   "source": [
    "# üßº Final Preprocessing Pipeline\n",
    "\n",
    "This notebook performs final preprocessing on both `train.csv` and `test.csv` using consistent imputation strategies and missing value flags, based on prior feature importance analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde58e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load raw data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Save target and ID before dropping\n",
    "y = train['Personality']\n",
    "train_ids = train['id']\n",
    "test_ids = test['id']\n",
    "\n",
    "train = train.drop(columns=['id', 'Personality'])\n",
    "test = test.drop(columns=['id'])\n",
    "\n",
    "# Define features\n",
    "binary_cols = ['Stage_fear', 'Drained_after_socializing']\n",
    "numeric_cols = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside',\n",
    "                'Friends_circle_size', 'Post_frequency']\n",
    "\n",
    "# Encode Yes/No to 1/0 before imputing\n",
    "for col in binary_cols:\n",
    "    train[col] = train[col].map({'Yes': 1, 'No': 0})\n",
    "    test[col] = test[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "binary_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', add_indicator=True))\n",
    "])\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_cols),\n",
    "    ('bin', binary_pipeline, binary_cols)\n",
    "])\n",
    "\n",
    "# Fit-transform train, transform test\n",
    "X_train = preprocessor.fit_transform(train)\n",
    "X_test = preprocessor.transform(test)\n",
    "\n",
    "# Convert missing flags from True/False to 0/1\n",
    "X_train = X_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "\n",
    "# Use get_feature_names_out to safely get correct column names\n",
    "column_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Build final DataFrames\n",
    "df_train_processed = pd.DataFrame(X_train, columns=column_names)\n",
    "df_test_processed = pd.DataFrame(X_test, columns=column_names)\n",
    "\n",
    "# Add back ID and target\n",
    "df_train_processed.insert(0, 'id', train_ids)\n",
    "df_train_processed['Personality'] = y\n",
    "\n",
    "df_test_processed.insert(0, 'id', test_ids)\n",
    "\n",
    "# Save processed files\n",
    "df_train_processed.to_csv('../data/train_processed.csv', index=False)\n",
    "df_test_processed.to_csv('../data/test_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18524, 16)\n",
      "Test shape: (6175, 15)\n",
      "\n",
      "Any NaNs in train: False\n",
      "Any NaNs in test: False\n",
      "\n",
      "‚úÖ Validation for train.csv:\n",
      "num__missingindicator_Time_spent_Alone: 1190 (expected 1190) ‚úì\n",
      "num__missingindicator_Social_event_attendance: 1180 (expected 1180) ‚úì\n",
      "num__missingindicator_Going_outside: 1466 (expected 1466) ‚úì\n",
      "num__missingindicator_Friends_circle_size: 1054 (expected 1054) ‚úì\n",
      "num__missingindicator_Post_frequency: 1264 (expected 1264) ‚úì\n",
      "bin__missingindicator_Stage_fear: 1893 (expected 1893) ‚úì\n",
      "bin__missingindicator_Drained_after_socializing: 1149 (expected 1149) ‚úì\n",
      "\n",
      "‚úÖ Validation for test.csv:\n",
      "num__missingindicator_Time_spent_Alone: 425 (expected 425) ‚úì\n",
      "num__missingindicator_Social_event_attendance: 397 (expected 397) ‚úì\n",
      "num__missingindicator_Going_outside: 466 (expected 466) ‚úì\n",
      "num__missingindicator_Friends_circle_size: 350 (expected 350) ‚úì\n",
      "num__missingindicator_Post_frequency: 408 (expected 408) ‚úì\n",
      "bin__missingindicator_Stage_fear: 598 (expected 598) ‚úì\n",
      "bin__missingindicator_Drained_after_socializing: 432 (expected 432) ‚úì\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Validation: Check consistency and correctness of processed data (safe version with real column names)\n",
    "\n",
    "# Reload and compare shapes\n",
    "train_check = pd.read_csv('../data/train_processed.csv')\n",
    "test_check = pd.read_csv('../data/test_processed.csv')\n",
    "\n",
    "print(\"Train shape:\", train_check.shape)\n",
    "print(\"Test shape:\", test_check.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nAny NaNs in train:\", train_check.isnull().values.any())\n",
    "print(\"Any NaNs in test:\", test_check.isnull().values.any())\n",
    "\n",
    "# Map original column names to real _missing flag columns\n",
    "missing_map = {}\n",
    "for prefix, cols in zip(['num', 'bin'], [numeric_cols, binary_cols]):\n",
    "    for col in cols:\n",
    "        missing_map[col] = f\"{prefix}__missingindicator_{col}\"\n",
    "\n",
    "\n",
    "# Validation for train.csv\n",
    "print(\"\\n‚úÖ Validation for train.csv:\")\n",
    "original_train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "for col, flag_col in missing_map.items():\n",
    "    raw_na_count = original_train[col].isnull().sum()\n",
    "    processed_count = train_check[flag_col].sum()\n",
    "\n",
    "    print(f\"{flag_col}: {processed_count} (expected {raw_na_count}) ‚úì\"\n",
    "          if processed_count == raw_na_count\n",
    "          else f\"{flag_col}: {processed_count} (‚ö† expected {raw_na_count})\")\n",
    "\n",
    "# Validation for test.csv\n",
    "print(\"\\n‚úÖ Validation for test.csv:\")\n",
    "original_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "for col, flag_col in missing_map.items():\n",
    "    raw_na_count = original_test[col].isnull().sum()\n",
    "    processed_count = test_check[flag_col].sum()\n",
    "\n",
    "    print(f\"{flag_col}: {processed_count} (expected {raw_na_count}) ‚úì\"\n",
    "          if processed_count == raw_na_count\n",
    "          else f\"{flag_col}: {processed_count} (‚ö† expected {raw_na_count})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f03f45",
   "metadata": {},
   "source": [
    "# üßº Final Preprocessing Summary\n",
    "\n",
    "This notebook performs safe and consistent preprocessing for `train.csv` and `test.csv`:\n",
    "\n",
    "### ‚úÖ Key Steps:\n",
    "- Encoded `Yes`/`No` binary features as `1`/`0`\n",
    "- Imputed:\n",
    "  - Numeric features ‚Üí median\n",
    "  - Binary features ‚Üí most frequent\n",
    "- Added `_missing` indicators for all features with `SimpleImputer(add_indicator=True)`\n",
    "- Used `get_feature_names_out()` to ensure indicator names match actual columns\n",
    "- Converted all `True/False` flags to `0`/`1`\n",
    "- Saved final outputs to:\n",
    "  - `data/train_processed.csv`\n",
    "  - `data/test_processed.csv`\n",
    "\n",
    "### üîç Validation:\n",
    "- Checked for absence of NaNs\n",
    "- Verified that `_missing` columns correctly reflect real missing values from raw datasets\n",
    "- Output shows `‚úì` if counts match, `‚ö†` if not\n",
    "\n",
    "This data is now ready for baseline modeling. üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
